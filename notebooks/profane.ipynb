{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1c9a90",
   "metadata": {},
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68715d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from profanity_check import predict, predict_prob\n",
    "# from better_profanity import profanity\n",
    "\n",
    "# # Configure better_profanity with English profanity list\n",
    "# profanity.load_censor_words()\n",
    "\n",
    "# def english_profanity_checker(text):\n",
    "#     \"\"\"\n",
    "#     Hybrid approach for detecting profanity in English text.\n",
    "#     Returns (is_profane, method, detected_terms)\n",
    "#     \"\"\"\n",
    "#     # Stage 1: Regex for common English profanity patterns\n",
    "#     # These patterns target common obfuscation techniques in English\n",
    "#     english_regex_patterns = [\n",
    "#         # F-word variations\n",
    "#         r'\\bf+[^\\w]*u+[^\\w]*c+[^\\w]*k+\\w*',\n",
    "#         r'\\bf+[^\\w]*\\*+[^\\w]*c+[^\\w]*k+\\w*',\n",
    "        \n",
    "#         # S-word variations\n",
    "#         r'\\bs+[^\\w]*h+[^\\w]*i+[^\\w]*t+\\w*',\n",
    "#         r'\\bs+[^\\w]*\\*+[^\\w]*\\*+[^\\w]*t+\\w*',\n",
    "        \n",
    "#         # Common racial slurs (being careful not to list them explicitly)\n",
    "#         r'\\bn+[^\\w]*i+[^\\w]*g+[^\\w]*g+[^\\w]*[^\\w]*r+\\w*',\n",
    "        \n",
    "#         # Common English curse words\n",
    "#         r'\\bb+[^\\w]*i+[^\\w]*t+[^\\w]*c+[^\\w]*h+\\w*',\n",
    "#         r'\\ba+[^\\w]*s+[^\\w]*s+[^\\w]*h+[^\\w]*o+[^\\w]*l+[^\\w]*e+\\w*',\n",
    "        \n",
    "#         # Common English sexual terms\n",
    "#         r'\\bp+[^\\w]*[uo]+[^\\w]*r+[^\\w]*n+\\w*',\n",
    "#         r'\\bp+[^\\w]*e+[^\\w]*n+[^\\w]*i+[^\\w]*s+\\w*',\n",
    "#     ]\n",
    "    \n",
    "#     # Check against regex patterns\n",
    "#     for pattern in english_regex_patterns:\n",
    "#         match = re.search(pattern, text, re.IGNORECASE)\n",
    "#         if match:\n",
    "#             return True, \"regex\", match.group(0)\n",
    "    \n",
    "#     # Stage 2: Dictionary-based check with better_profanity\n",
    "#     if profanity.contains_profanity(text):\n",
    "#         # Extract the profane terms\n",
    "#         censored = profanity.censor(text, '*')\n",
    "#         # Find the censored words\n",
    "#         words = text.split()\n",
    "#         censored_words = censored.split()\n",
    "#         profane_terms = []\n",
    "        \n",
    "#         for original, censored in zip(words, censored_words):\n",
    "#             if '*' in censored:\n",
    "#                 profane_terms.append(original)\n",
    "        \n",
    "#         return True, \"dictionary\", profane_terms\n",
    "    \n",
    "#     # Stage 3: ML-based detection for subtle cases\n",
    "#     probability = predict_prob([text])[0]\n",
    "#     if probability > 0.7:  # Adjustable threshold\n",
    "#         return True, \"machine_learning\", f\"ML detection (probability: {probability})\"\n",
    "    \n",
    "#     return False, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca206e9",
   "metadata": {},
   "source": [
    "# Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4f758ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from profanity_check import predict, predict_prob\n",
    "from better_profanity import profanity\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def english_profanity_checker(text):\n",
    "    \"\"\"\n",
    "    Hybrid approach for detecting profanity in English text.\n",
    "    Returns (is_profane, method, detected_terms)\n",
    "    \"\"\"\n",
    "    # Stage 1: Regex for common English profanity patterns\n",
    "    english_regex_patterns = [\n",
    "        r'\\bf+[^\\w]*u+[^\\w]*c+[^\\w]*k+\\w*',\n",
    "        r'\\bf+[^\\w]*\\*+[^\\w]*c+[^\\w]*k+\\w*',\n",
    "        r'\\bs+[^\\w]*h+[^\\w]*i+[^\\w]*t+\\w*',\n",
    "        r'\\bs+[^\\w]*\\*+[^\\w]*\\*+[^\\w]*t+\\w*',\n",
    "        r'\\bn+[^\\w]*i+[^\\w]*g+[^\\w]*g+[^\\w]*[^\\w]*r+\\w*',\n",
    "        r'\\bb+[^\\w]*i+[^\\w]*t+[^\\w]*c+[^\\w]*h+\\w*',\n",
    "        r'\\ba+[^\\w]*s+[^\\w]*s+[^\\w]*h+[^\\w]*o+[^\\w]*l+[^\\w]*e+\\w*',\n",
    "        r'\\bp+[^\\w]*[uo]+[^\\w]*r+[^\\w]*n+\\w*',\n",
    "        r'\\bp+[^\\w]*e+[^\\w]*n+[^\\w]*i+[^\\w]*s+\\w*',\n",
    "    ]\n",
    "    \n",
    "    # Check against regex patterns - find ALL matches\n",
    "    regex_matches = []\n",
    "    for pattern in english_regex_patterns:\n",
    "        matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            regex_matches.append(match.group(0))\n",
    "    \n",
    "    if regex_matches:\n",
    "        return True, \"regex\", regex_matches\n",
    "    \n",
    "    # Stage 2: Dictionary-based check with better_profanity\n",
    "    if profanity.contains_profanity(text):\n",
    "        censored = profanity.censor(text, '*')\n",
    "        words = text.split()\n",
    "        censored_words = censored.split()\n",
    "        profane_terms = []\n",
    "        \n",
    "        for original, censored in zip(words, censored_words):\n",
    "            if '*' in censored:\n",
    "                profane_terms.append(original)\n",
    "        \n",
    "        return True, \"dictionary\", profane_terms\n",
    "    \n",
    "    # Stage 3: ML-based detection for subtle cases\n",
    "    try:\n",
    "        probability = predict_prob([text])[0]\n",
    "        if probability > 0.7:  # Adjustable threshold\n",
    "            return True, \"machine_learning\", [f\"ML detection (probability: {probability})\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: ML detection failed with error: {e}\")\n",
    "    \n",
    "    return False, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3dfd1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity.load_censor_words()\n",
    "\n",
    "def process_file(filepath):\n",
    "    \"\"\"Process a single JSON file and extract profanity information\"\"\"\n",
    "    file_id = os.path.basename(filepath)\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return []\n",
    "    \n",
    "    results = []\n",
    "    for entry in data:\n",
    "        text = entry.get('text', '')\n",
    "        is_profane, method, profane_terms = english_profanity_checker(text, api_key=\"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\")\n",
    "        \n",
    "        if is_profane:\n",
    "            # Ensure profane_terms is a list\n",
    "            if not isinstance(profane_terms, list):\n",
    "                profane_terms = [profane_terms]\n",
    "                \n",
    "            # For multiple profane terms, create separate entries\n",
    "            for term in profane_terms:\n",
    "                results.append({\n",
    "                    'file_id': file_id,\n",
    "                    'timestamp_start': entry.get('stime'),\n",
    "                    'timestamp_end': entry.get('etime'),\n",
    "                    'speaker': entry.get('speaker'),\n",
    "                    'profane_term': term,\n",
    "                    'sentence': text,\n",
    "                    'detection_method': method\n",
    "                })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    \"\"\"Process all JSON files in a directory and compile profanity results\"\"\"\n",
    "    all_profanity_data = []\n",
    "    \n",
    "    # List all JSON files in the directory\n",
    "    json_files = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith('.json')]\n",
    "    print(f\"Found {len(json_files)} JSON files to process\")\n",
    "    \n",
    "    # Process each file\n",
    "    for i, file_path in enumerate(json_files):\n",
    "        file_results = process_file(file_path)\n",
    "        all_profanity_data.extend(file_results)\n",
    "        \n",
    "        # Print progress every 25 files\n",
    "        if (i + 1) % 25 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(json_files)} files\")\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    df_profanity = pd.DataFrame(all_profanity_data)\n",
    "    \n",
    "    # Sort by file_id and timestamp_start for better readability\n",
    "    if not df_profanity.empty:\n",
    "        df_profanity = df_profanity.sort_values(['file_id', 'timestamp_start'])\n",
    "    \n",
    "    return df_profanity\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process files and generate CSV output\"\"\"\n",
    "    # Replace with your actual directory path\n",
    "    directory_path = \"../All_Conversations/\"\n",
    "    output_csv_path = \"profanity_report_llm.csv\"\n",
    "    \n",
    "    print(f\"Starting profanity detection on files in {directory_path}\")\n",
    "    \n",
    "    # Process all files and get DataFrame\n",
    "    df_results = process_directory(directory_path)\n",
    "    \n",
    "    if df_results.empty:\n",
    "        print(\"No profanity found or no valid files processed\")\n",
    "        return\n",
    "    \n",
    "    # Save to CSV\n",
    "    df_results.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Results saved to {output_csv_path}\")\n",
    "    print(f\"Found {len(df_results)} instances of profanity across {df_results['file_id'].nunique()} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f455d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting profanity detection on files in ../All_Conversations/\n",
      "Found 250 JSON files to process\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Can be used for Bulk operations\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting profanity detection on files in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Process all files and get DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m df_results = \u001b[43mprocess_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_results.empty:\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo profanity found or no valid files processed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mprocess_directory\u001b[39m\u001b[34m(directory_path)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Process each file\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(json_files):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     file_results = \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     all_profanity_data.extend(file_results)\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# Print progress every 25 files\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mprocess_file\u001b[39m\u001b[34m(filepath)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m     16\u001b[39m     text = entry.get(\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     is_profane, method, profane_terms = \u001b[43menglish_profanity_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgsk_BFFEU9w7hf0asfbG5HNvWGdyb3FYf4KHrDJyoUWFAnntCA3C6Eil\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_profane:\n\u001b[32m     20\u001b[39m         \u001b[38;5;66;03m# Ensure profane_terms is a list\u001b[39;00m\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(profane_terms, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 129\u001b[39m, in \u001b[36menglish_profanity_checker\u001b[39m\u001b[34m(text, use_llm, api_key)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Stage 4: LLM-based detection as a last resort\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_llm:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     is_profane, profane_terms = \u001b[43mcheck_profanity_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_profane:\n\u001b[32m    131\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mllm\u001b[39m\u001b[33m\"\u001b[39m, profane_terms)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mcheck_profanity_with_llm\u001b[39m\u001b[34m(text, api_key)\u001b[39m\n\u001b[32m     34\u001b[39m     user_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mAnalyze this text for any profanity or offensive language: \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[33mIf profanity or offensive language is found, return a JSON object with this format:\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \n\u001b[32m     42\u001b[39m \u001b[33mOnly respond with the JSON object, nothing else.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m         response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta-llama/llama-4-scout-17b-16e-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Using Llama 3.1 for best performance\u001b[39;49;00m\n\u001b[32m     47\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Low temperature for consistent results\u001b[39;49;00m\n\u001b[32m     52\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson_object\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m         result_text = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     57\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/groq/resources/chat/completions.py:322\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, seed, service_tier, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    167\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    168\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    198\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    199\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    200\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    202\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/groq/_base_client.py:1225\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1212\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1213\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1220\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1221\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1222\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1223\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1224\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/groq/_base_client.py:917\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    915\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/groq/_base_client.py:953\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m    950\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, request.method, request.url)\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    959\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpx/_client.py:928\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    927\u001b[39m     response.close()\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpx/_client.py:922\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpx/_models.py:881\u001b[39m, in \u001b[36mResponse.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    877\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    878\u001b[39m \u001b[33;03mRead and return the response content.\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_content\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m     \u001b[38;5;28mself\u001b[39m._content = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m.iter_bytes())\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpx/_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpx/_models.py:959\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker.flush():\n\u001b[32m    957\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[32m--> \u001b[39m\u001b[32m959\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpx/_models.py:972\u001b[39m, in \u001b[36mResponse.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    970\u001b[39m \u001b[38;5;28mself\u001b[39m.is_closed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpx/_client.py:159\u001b[39m, in \u001b[36mBoundSyncStream.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    157\u001b[39m elapsed = time.perf_counter() - \u001b[38;5;28mself\u001b[39m._start\n\u001b[32m    158\u001b[39m \u001b[38;5;28mself\u001b[39m._response.elapsed = datetime.timedelta(seconds=elapsed)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpx/_transports/default.py:132\u001b[39m, in \u001b[36mResponseStream.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._httpcore_stream, \u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:416\u001b[39m, in \u001b[36mPoolByteStream.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._stream, \u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    414\u001b[39m         \u001b[38;5;28mself\u001b[39m._stream.close()\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_optional_thread_lock\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_requests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosing\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_assign_requests_to_connections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/prodigal/lib/python3.11/site-packages/httpcore/_synchronization.py:267\u001b[39m, in \u001b[36mThreadLock.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    265\u001b[39m     \u001b[38;5;28mself\u001b[39m._lock = threading.Lock()\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ThreadLock:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m._lock.acquire()\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "main() # Can be used for Bulk operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e1f1a",
   "metadata": {},
   "source": [
    "# With LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2019e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from profanity_check import predict, predict_prob\n",
    "from better_profanity import profanity\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "\n",
    "# Configure better_profanity with English profanity list\n",
    "profanity.load_censor_words()\n",
    "\n",
    "def check_profanity_with_llm(text, api_key=None):\n",
    "    \"\"\"Use Groq's LLM to check for subtle or contextual profanity\"\"\"\n",
    "    # Initialize Groq client\n",
    "    api_key = api_key or os.environ.get(\"GROQ_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"Warning: No Groq API key provided. Skipping LLM check.\")\n",
    "        return False, None\n",
    "    \n",
    "    client = Groq(api_key=api_key)\n",
    "    \n",
    "    # Create system prompt for effective profanity detection\n",
    "    system_prompt = \"\"\"You are a specialized content moderation AI designed to detect profanity and offensive language in text.\n",
    "Your task is to identify subtle forms of profanity that might be missed by traditional filters, including:\n",
    "\n",
    "1. Contextual profanity where words are inappropriate in specific contexts\n",
    "2. Disguised profanity using alternate spellings, characters, or separators\n",
    "3. Implicit offensive language that uses euphemisms or coded language\n",
    "4. Domain-specific insults or derogatory terms\n",
    "5. Phrases that are offensive in nature even without traditional profane words\n",
    "\n",
    "Be thorough in your analysis, but avoid flagging non-offensive technical terms, medical terminology, or legitimate discussions that use potentially problematic words in appropriate contexts.\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"Analyze this text for any profanity or offensive language: \"{text}\"\n",
    "\n",
    "If profanity or offensive language is found, return a JSON object with this format:\n",
    "{{\"detected\": true, \"terms\": [\"term1\", \"term2\", ...]}}\n",
    "\n",
    "If no profanity or offensive language is found:\n",
    "{{\"detected\": false, \"terms\": []}}\n",
    "\n",
    "Only respond with the JSON object, nothing else.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Using Llama 3.1 for best performance\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.1,  # Low temperature for consistent results\n",
    "            max_tokens=200,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        result_text = response.choices[0].message.content\n",
    "        try:\n",
    "            result = json.loads(result_text)\n",
    "            \n",
    "            # If profanity was found\n",
    "            if result.get(\"detected\", False) and result.get(\"terms\", []):\n",
    "                return True, result.get(\"terms\", [])\n",
    "            \n",
    "            return False, None\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: LLM returned non-JSON response: {result_text}\")\n",
    "            return False, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: LLM profanity check failed with error: {e}\")\n",
    "        return False, None\n",
    "\n",
    "def english_profanity_checker(text, use_llm=False, api_key=None):\n",
    "    \"\"\"\n",
    "    Hybrid approach for detecting profanity in English text.\n",
    "    Returns (is_profane, method, detected_terms)\n",
    "    \n",
    "    Parameters:\n",
    "    - text: The text to check for profanity\n",
    "    - use_llm: Whether to use LLM as a final check (default: True)\n",
    "    - api_key: Groq API key (if None, will look for GROQ_API_KEY environment variable)\n",
    "    \"\"\"\n",
    "    # Stage 1: Regex for common English profanity patterns\n",
    "    english_regex_patterns = [\n",
    "        r'\\bf+[^\\w]*u+[^\\w]*c+[^\\w]*k+\\w*',\n",
    "        r'\\bf+[^\\w]*\\*+[^\\w]*c+[^\\w]*k+\\w*',\n",
    "        r'\\bs+[^\\w]*h+[^\\w]*i+[^\\w]*t+\\w*',\n",
    "        r'\\bs+[^\\w]*\\*+[^\\w]*\\*+[^\\w]*t+\\w*',\n",
    "        r'\\bn+[^\\w]*i+[^\\w]*g+[^\\w]*g+[^\\w]*[^\\w]*r+\\w*',\n",
    "        r'\\bb+[^\\w]*i+[^\\w]*t+[^\\w]*c+[^\\w]*h+\\w*',\n",
    "        r'\\ba+[^\\w]*s+[^\\w]*s+[^\\w]*h+[^\\w]*o+[^\\w]*l+[^\\w]*e+\\w*',\n",
    "        r'\\bp+[^\\w]*[uo]+[^\\w]*r+[^\\w]*n+\\w*',\n",
    "        r'\\bp+[^\\w]*e+[^\\w]*n+[^\\w]*i+[^\\w]*s+\\w*',\n",
    "    ]\n",
    "    \n",
    "    # Check against regex patterns - find ALL matches\n",
    "    regex_matches = []\n",
    "    for pattern in english_regex_patterns:\n",
    "        matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            regex_matches.append(match.group(0))\n",
    "    \n",
    "    if regex_matches:\n",
    "        return True, \"regex\", regex_matches\n",
    "    \n",
    "    # Stage 2: Dictionary-based check with better_profanity\n",
    "    if profanity.contains_profanity(text):\n",
    "        censored = profanity.censor(text, '*')\n",
    "        words = text.split()\n",
    "        censored_words = censored.split()\n",
    "        profane_terms = []\n",
    "        \n",
    "        for original, censored in zip(words, censored_words):\n",
    "            if '*' in censored:\n",
    "                profane_terms.append(original)\n",
    "        \n",
    "        return True, \"dictionary\", profane_terms\n",
    "    \n",
    "    # Stage 3: ML-based detection for subtle cases\n",
    "    try:\n",
    "        probability = predict_prob([text])[0]\n",
    "        if probability > 0.7:  # Adjustable threshold\n",
    "            return True, \"machine_learning\", [f\"ML detection (probability: {probability})\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: ML detection failed with error: {e}\")\n",
    "    \n",
    "    # Stage 4: LLM-based detection as a last resort\n",
    "    if use_llm:\n",
    "        is_profane, profane_terms = check_profanity_with_llm(text, api_key)\n",
    "        if is_profane:\n",
    "            print(\"llm\", profane_terms)\n",
    "            return True, \"llm\", profane_terms\n",
    "            \n",
    "    \n",
    "    return False, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eab5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to process files and generate CSV output\"\"\"\n",
    "    # Replace with your actual directory path\n",
    "    directory_path = \"../All_Conversations/\"\n",
    "    output_csv_path = \"profanity_report_llm.csv\"\n",
    "    \n",
    "    print(f\"Starting profanity detection on files in {directory_path}\")\n",
    "    \n",
    "    # Process all files and get DataFrame\n",
    "    df_results = process_directory(directory_path)\n",
    "    \n",
    "    if df_results.empty:\n",
    "        print(\"No profanity found or no valid files processed\")\n",
    "        return\n",
    "    \n",
    "    # Save to CSV\n",
    "    df_results.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Results saved to {output_csv_path}\")\n",
    "    print(f\"Found {len(df_results)} instances of profanity across {df_results['file_id'].nunique()} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03d37caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting profanity detection on files in ../All_Conversations/\n",
      "Found 250 JSON files to process\n",
      "Processed 25/250 files\n",
      "Processed 50/250 files\n",
      "Processed 75/250 files\n",
      "Processed 100/250 files\n",
      "Processed 125/250 files\n",
      "Processed 150/250 files\n",
      "Processed 175/250 files\n",
      "Processed 200/250 files\n",
      "Processed 225/250 files\n",
      "Processed 250/250 files\n",
      "Results saved to profanity_report_llm.csv\n",
      "Found 155 instances of profanity across 39 files\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodigal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
